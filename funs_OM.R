### ------------------------------------------------------------------------ ###
### functions for creating operating models (OMs) ####
### ------------------------------------------------------------------------ ###

### ------------------------------------------------------------------------ ###
### convert Beverton-Holt stock-recruitment model ####
### ------------------------------------------------------------------------ ###
### formulation with steepness, virgin biomass -> a & b

bevholtSV_to_bevholt <- function(sr) {
  sr_new <- sr ### duplicate model
  model(sr_new) <- "bevholt" ### change model type to bevholt
  ### convert parameters into normal bevholt parameters
  sr_pars <- abPars(model = "bevholt", spr0 = (params(sr)["spr0"]),
                    s = (params(sr)["s"]), v = (params(sr)["v"]))
  dimnames(sr_pars$a)$params <- "a"
  dimnames(sr_pars$b)$params <- "b"
  ### combine all parameters and insert them
  sr_pars <- rbind(rbind(sr_pars$a, sr_pars$b), params(sr))
  params(sr_new) <- sr_pars
  ### also insert some more slots
  ssb(sr_new) <- ssb(sr)
  rec(sr_new) <- rec(sr)
  logLik(sr_new) <- logLik(sr)
  details(sr_new) <- details(sr)
  residuals(sr_new) <- residuals(sr)
  fitted(sr_new) <- fitted(sr)
  
  return(sr_new)
}

### ------------------------------------------------------------------------ ###
### create operating model ####
### ------------------------------------------------------------------------ ###
### this function creates the elements required for an OM to run an MSE,
### e.g. OM stock, stock-recruitment model, survey indices, etc.
create_OM <- function(stk_data, idx_data, 
                      n = 1000, n_years = 100, yr_data = 2020, 
                      ### discard survival
                      disc_survival_OM = 0.5, ### for OM
                      disc_survival_MP = disc_survival_OM, ### data seen by MP
                      ### natural mortality
                      M_alternative = NULL, ### 1 value (const.) or M@age
                      M_alternative_mult = FALSE,
                      ### stf settings
                      stf_nyrs = 5,
                      ### intermediate year
                      int_yr = FALSE,
                      int_yr_add = FALSE,
                      int_yr_catch = NA,
                      int_yr_catch_split = TRUE, ### account for disc survival
                      ### SAM
                      SAM_conf = NULL, SAM_conf_full = FALSE, SAM_NA_rm = TRUE,
                      SAM_idx_weight = FALSE,
                      SAM_newtonsteps = 0, SAM_rel.tol = 0.001,
                      ### biological data
                      n_sample_yrs = 5, 
                      ### stock-recruit modelling
                      sr_model = "bevholtSV", sr_start = NULL,
                      sr_fixed = list(),
                      sr_yrs_rm = NULL, ### remove recruitment years?
                      sr_parallel = 10, sr_ar_check = TRUE,
                      ### process error
                      process_error = TRUE, 
                      ### observation error (catch)
                      catch_oem_error = TRUE,
                      ### indices
                      idxB = 1, ### FALSE, index name or numeric index
                      ### length data
                      idxL = TRUE, ALKs, 
                      ALK_yrs = NULL, ### subset ALK years?
                      ALK_yrs_sample = NULL, ### sample only from some years?
                      length_samples = 2000,
                      ### PA status for 2 over 3 rule
                      PA_status = TRUE, ### status evaluation success rate
                      ### reference points
                      refpts = list(),
                      ### some definitions
                      stock_id = "ple.27.7e",
                      OM = "baseline",
                      save = TRUE, ### save OM objects to files?
                      return = FALSE ### return OM objects?
) {#browser()
  
  ### ---------------------------------------------------------------------- ###
  ### preparation for alternative OMs ####
  stk_data_input <- stk_data
  
  ### ---------------------------------------------------------------------- ###
  ### Discard survival ####
  
  ### if survival = 1 (all discards die),
  ### include small proportion to avoid computational issues with observations
  if (identical(disc_survival_OM, 1)) disc_survival_OM <- 1 - 0.001
  
  ### OM data
  if (isTRUE(disc_survival_OM > 0)) {
    message(paste0("OM - Using discard survival ", disc_survival_OM))
    discards.n(stk_data)[is.na(discards.n(stk_data))] <- 0
    discards.wt(stk_data)[is.na(discards.wt(stk_data))] <- 0
    discards.n(stk_data)[] <- discards.n(stk_data) * (1 - disc_survival_OM)
    discards(stk_data) <- computeDiscards(stk_data)
    catch(stk_data) <- computeCatch(stk_data, slot = "all")
  }
  
  ### ---------------------------------------------------------------------- ###
  ### alternative M scenario? ####
  if (!is.null(M_alternative)) {
    message("using alternative M scenario")
    if (isTRUE(M_alternative_mult)) {
      m(stk_data) <- m(stk_data) * M_alternative
    } else {
      m(stk_data)[] <- M_alternative
    }
  }
  
  ### ---------------------------------------------------------------------- ###
  ### fit SAM ####
  message("fitting SAM")
  fit <- FLR_SAM(stk_data, idx_data, conf = SAM_conf, conf_full = SAM_conf_full,
                 idx_weight = SAM_idx_weight, NA_rm = SAM_NA_rm)
  SAM_conf <- fit$conf
  ### fit SAM with relaxed convergence
  fit_mse <- FLR_SAM(stk_data, idx_data, conf = SAM_conf,
                     conf_full = SAM_conf_full, idx_weight = SAM_idx_weight,
                     NA_rm = SAM_NA_rm,
                     newtonsteps = SAM_newtonsteps, rel.tol = SAM_rel.tol)
  ### get initial parameters
  pars_ini <- getpars(fit_mse)
  
  ### ---------------------------------------------------------------------- ###
  ### create FLStock ####
  message("create OM FLStock")
  stk <- SAM2FLStock(object = fit, stk = stk_data)
  stk_orig <- stk
  
  ### ---------------------------------------------------------------------- ###
  ### projection years ####
  yrs_hist <- as.numeric(dimnames(stk)$year)
  yrs_proj <- seq(from = dims(stk)$maxyear + 1, length.out = n_years)
  n_years_new <- n_years
  ### does assessment include intermediate year?
  if (isTRUE(int_yr)) {
    yrs_hist <- yrs_hist[-length(yrs_hist)]
    yrs_proj <- seq(from = dims(stk)$maxyear + 0, length.out = n_years)
    n_years_new <- n_years - 1
  }
  ### add intermediate year to OM?
  if (isTRUE(int_yr_add)) {
    #yrs_hist <- c(yrs_hist, max(yrs_hist) + 1)
    n_years_new <- n_years + 1
    yrs_proj <- seq(from = dims(stk)$maxyear + 1, length.out = n_years_new)
    int_yr_yr <- min(yrs_proj)
  }
  yrs_mse <- sort(unique(c(yrs_hist, yrs_proj)))
  
  ### ---------------------------------------------------------------------- ###
  ### add uncertainty with variance-covariance matrix ####
  message("add uncertainty to OM with variance-covariance matrix")
  
  ### add iteration dimension
  stk <- FLCore::propagate(stk, n)
  ### add uncertainty estimated by SAM as iterations
  set.seed(1)
  uncertainty <- SAM_uncertainty(fit = fit, n = n)
  ### add noise to stock
  stock.n(stk)[] <- uncertainty$stock.n
  stock(stk)[] <- computeStock(stk)
  ### add noise to F
  harvest(stk)[] <- uncertainty$harvest
  ### add noise to catch numbers
  catch.n(stk)[, ac(yrs_hist)] <- uncertainty$catch.n[, ac(yrs_hist)]
  catch(stk) <- computeCatch(stk)
  ### update landings/discards
  stk_tmp <- stk
  landings.n(stk) <-  catch.n(stk_tmp) * 
    landings.n(stk_tmp)/(landings.n(stk_tmp) + discards.n(stk_tmp))
  landings(stk) <- computeLandings(stk)
  discards.n(stk) <-  catch.n(stk_tmp) * 
    discards.n(stk_tmp)/(landings.n(stk_tmp) + discards.n(stk_tmp))
  discards(stk) <- computeDiscards(stk)
  
  ### ---------------------------------------------------------------------- ###
  ### discard rate ####
  ### if missing, add discard rate to avoid later issues when projecting
  if (isTRUE(int_yr)) {
    yr_max <- range(stk)[["maxyear"]]
    if (all(is.na(catch(stk)[, ac(yr_max)]))) {
      landings.n(stk)[, ac(yr_max)] <- 
        (landings.n(stk)/catch.n(stk))[, ac(yr_data)]
      discards.n(stk)[, ac(yr_max)] <- 
        (discards.n(stk)/catch.n(stk))[, ac(yr_data)]
    }
  }
  
  ### ---------------------------------------------------------------------- ###
  ### extend stock for MSE simulation ####
  message("extend OM stock for projection")
  stk_stf <- stf(stk, n_years_new, wts.nyears = stf_nyrs, 
                 disc.nyears = stf_nyrs)
  
  ### ---------------------------------------------------------------------- ###
  ### biological data for OM ####
  message("create biological and fishery data for projection")
  ### Resample weights, maturity and natural mortality from the last X years 
  ### set up an array with one resampled year for each projection year 
  ### (including intermediate year) and replicate
  ### use the same resampled year for all biological parameters
  set.seed(2)
  ### use last X data years to sample biological parameters
  sample_yrs <- seq(to = yr_data, length.out = n_sample_yrs)
  ### get year position of sample years
  sample_yrs_pos <- which(dimnames(stk_stf)$year %in% sample_yrs)
  
  ### create samples for biological data (weights, etc.)
  ### the historical biological parameters are identical for all iterations
  ### and consequently do not need to be treated individually
  ### (but keep age structure)
  ### create vector with resampled years
  bio_samples <- sample(x = sample_yrs_pos, 
                        size = (n_years_new) * n, replace = TRUE)
  ### years to be populated
  bio_yrs <- which(dimnames(stk_stf)$year %in% 
                     (yr_data + 1):dims(stk_stf)$maxyear)
  ### insert values
  catch.wt(stk_stf)[, bio_yrs] <- c(catch.wt(stk)[, bio_samples,,,, 1])
  stock.wt(stk_stf)[, bio_yrs] <- c(stock.wt(stk)[, bio_samples,,,, 1])
  landings.wt(stk_stf)[, bio_yrs] <- c(landings.wt(stk)[, bio_samples,,,, 1])
  discards.wt(stk_stf)[, bio_yrs] <- c(discards.wt(stk)[, bio_samples,,,, 1])
  m(stk_stf)[, bio_yrs] <- c(m(stk)[, bio_samples,,,, 1])
  mat(stk_stf)[, bio_yrs] <- c(mat(stk)[, bio_samples,,,, 1])
  
  ### do the same for selectivity
  ### use replicate specific selectivity and sample these
  sel_samples <- sample(x = sample_yrs_pos, 
                        size = n_years_new * n, replace = TRUE)
  ### selectivity differs by replicate -> keep replicate specific values
  sel_samples_iter <- split(sel_samples, 
                            f = rep(seq(n), each = n_years_new))
  sel_vals <- as.numeric(sapply(seq(n), function(x) {
    c(harvest(stk)[, sel_samples_iter[[x]],,,, x])
  }))
  ### insert
  harvest(stk_stf)[, bio_yrs] <- sel_vals

  
  ### ---------------------------------------------------------------------- ###
  ### stock recruitment ####
  message("creating stock-recruitment model")
  ### fit stock-recruitment model and get residuals from smoothed residuals
  
  ### create FLSR object
  sr <- as.FLSR(stk_stf, model = sr_model)
  if (!is.null(sr_start)) sr <- window(sr, start = sr_start)
  if (!is.null(sr_yrs_rm)) rec(sr)[, ac("sr_yrs_rm")] <- NA
  ### fit model individually to each iteration and suppress output to screen
  if (isFALSE(sr_parallel) | isTRUE(sr_parallel == 0)) {
    sr <- fmle(sr, method = 'L-BFGS-B', fixed = sr_fixed, 
               control = list(trace = 0))
  } else {
    ### run in parallel
    message("fitting stock-recruitment model in parallel")
    cl_tmp <- makeCluster(as.numeric(sr_parallel))
    registerDoParallel(cl_tmp)
    sr <- fmle_parallel(sr, cl_tmp, method = 'L-BFGS-B', fixed = sr_fixed)
    stopCluster(cl_tmp)
  }
  ### run again for failed iterations - if needed
  pos_error <- which(is.na(params(sr)[1]))
  if (isTRUE(length(pos_error) > 0)) {
    message("repeating failed iterations")
    sr_corrected <- FLCore::iter(sr, pos_error)
    sr_corrected <- fmle(sr_corrected, method = 'L-BFGS-B', fixed = sr_fixed,
                         control = list(trace = 0))
    sr[,,,,, pos_error] <- sr_corrected[]
    params(sr)[, pos_error] <- params(sr_corrected)
  }
  if (identical(sr_model, "bevholtSV")) {
    sr <- bevholtSV_to_bevholt(sr)
  }
  
  ### check autocorrelation of residuals for SAM median perception
  sr_med <- as.FLSR(stk_orig, model = sr_model)
  if (!is.null(sr_start)) sr_med <- window(sr_med, start = sr_start)
  if (!is.null(sr_yrs_rm)) rec(sr_med)[, ac("sr_yrs_rm")] <- NA
  sr_med <- fmle(sr_med, method = 'L-BFGS-B', fixed = sr_fixed,
                 control = list(trace = 0))
  sr_acf <- acf(residuals(sr_med), plot = FALSE, na.action = na.exclude)
  sr_rho <- sr_acf$acf[2]
  ### only include if lag-1 auto-correlation is above threshold
  ci <- qnorm((1 + 0.95)/2)/sqrt(sr_acf$n.used)
  if (isTRUE(sr_rho >= ci)) {
    message(paste0("residual lag-1 autocorrelation ",
                   round(sr_rho, 2), " above threshold of ", round(ci, 2)))
  } else {
    message(paste0("residual lag-1 autocorrelation ",
                   round(sr_rho, 2), " below threshold of ", round(ci, 2)))
  }
  if (isFALSE(sr_ar_check) | sr_rho < ci) {
    message("- NOT including auto-correlation")
  } else {
    message("- including auto-correlation")
  }
  
  ### generate residuals for MSE
  ### years with missing residuals
  yrs_res <- colnames(rec(sr))[which(is.na(iterMeans(rec(sr))))]
  ### go through iterations and create residuals
  ### use kernel density to create smooth distribution of residuals
  ### and sample from this distribution
  res_new <- foreach(iter_i = seq(dim(sr)[6])) %do% {
    set.seed(iter_i)
    ### get residuals for current iteration
    res_i <- c(FLCore::iter(residuals(sr), iter_i))
    res_i <- res_i[!is.na(res_i)]
    ### calculate kernel density of residuals
    density <- density(x = res_i)
    ### sample residuals
    mu <- sample(x = res_i, size = length(yrs_res), replace = TRUE)
    ### "smooth", i.e. sample from density distribution
    res_new <- rnorm(n = length(yrs_res), mean = mu, sd = density$bw)
    ### "add" autocorrelation
    if (isTRUE(sr_ar_check) & isTRUE(sr_rho >= ci)) {
      sr_acf_i <- acf(res_i, lag.max = 1, plot = FALSE, na.action = na.exclude)
      sr_rho_i <- sr_acf_i$acf[2]
      res_ac <- rep(0, length(yrs_res))
      res_ac[1] <- sr_rho * tail(res_i, 1) + sqrt(1 - sr_rho^2) * res_new[1]
      for (r in 2:length(res_ac)) {
        res_ac[r] <- sr_rho * res_ac[r - 1] + sqrt(1 - sr_rho^2) * res_new[r]
      }
      res_new <- res_ac
    }
    return(res_new)
  }
  ### insert into model
  residuals(sr)[, yrs_res] <- unlist(res_new)
  ### exponentiate residuals to get factor
  residuals(sr) <- exp(residuals(sr))
  sr_res <- residuals(sr)
  
  ### ---------------------------------------------------------------------- ###
  ### process noise ####
  ### create FLQuant with process noise
  ### this will be added to the values obtained from fwd() in the MSE
  if (isTRUE(process_error)) {
    message("including survival process error")
    ### create noise for process error
    set.seed(3)
    proc_res <- stock.n(stk_stf) %=% 0 ### template FLQuant
    proc_res[] <- stats::rnorm(n = length(proc_res), mean = 0, 
                               sd = uncertainty$proc_error)
    ### the proc_res values follow a normal distribution,
    ### exponentiate to get log-normal residuals
    proc_res <- exp(proc_res)
    ### proc_res is a factor by which the numbers at age are multiplied
    ### for historical period, numbers already include process error from SAM
    ### -> remove deviation
    proc_res[, dimnames(proc_res)$year <= yr_data] <- 1
    ### remove deviation for first age class (recruits)
    proc_res[1, ] <- 1
  } else {
    message("NOT including survival process error")
    proc_res <- 1
  }
  ### try saving in stock recruitment model ... 
  ### this gets passed on to the projection module
  # fitted(sr) <- proc_res
  
  ### ---------------------------------------------------------------------- ###
  ### stf for intermediate year ####
  if (isTRUE(int_yr_add)) {
    message("include intermediate year forecast")
    int_yr_value <- int_yr_catch
    if (isTRUE(disc_survival_OM > 0) & isTRUE(int_yr_catch_split)) {
      ### if some discards survive, adjust catch for this survival
      d_rate <- yearMeans(tail(discards(stk_data_input)/
                             catch(stk_data_input), stf_nyrs))
      c_prop <- (1 - d_rate + d_rate * (1 - disc_survival_OM))
      int_yr_value <- c(int_yr_value * c_prop)
      message("-> include discard survival in intermediate year")
    }
    ctrl_int <- fwdControl(data.frame(year = int_yr_yr, 
                                      quant = "catch", 
                                      value = int_yr_value))
    ### project forward for intermediate year
    stk_int <- fwd(stk_stf, control = ctrl_int, sr = sr, 
                   deviances = residuals(sr))
    
    ### add process noise
    stock.n(stk_int) <- stock.n(stk_int) * proc_res
    stock(stk_int)[] <- computeStock(stk_int)
  }
  
  stk_fwd <- stk_int
  
  ### ---------------------------------------------------------------------- ###
  ### biological data for OEM ####
  message("OEM biological data")
  ### base on OM stock
  stk_oem <- stk_fwd
  
  ### if alternative M scenario, MP does not know this
  if (!is.null(M_alternative)) {
    ### adapt M in historical years
    ### future years changed later with other biological data
    M_yrs <- dimnames(stk_data_input)$year
    m(stk_oem)[, M_yrs] <- m(stk_data_input)
  }
  
  ### projection years
  proj_yrs <- (yr_data + 1):range(stk_oem)[["maxyear"]]
  
  ### use means of sampled values for projection period
  stock.wt(stk_oem)[, ac(proj_yrs)] <- 
    yearMeans(stock.wt(stk_oem)[, ac(sample_yrs)])
  m(stk_oem)[, ac(proj_yrs)] <- yearMeans(m(stk_oem)[, ac(sample_yrs)])
  mat(stk_oem)[, ac(proj_yrs)] <- yearMeans(mat(stk_oem)[, ac(sample_yrs)])
  ### remove stock assessment results
  stock.n(stk_oem)[] <- stock(stk_oem)[] <- harvest(stk_oem)[] <- NA
  
  ### ---------------------------------------------------------------------- ###
  ### catch - discard survival and catch observations ####
  ### catch survival in OM and MP may be different
  ### -> include as observation error
  
  ### MP catch observations (with observed discard survival)

  ### historical years - insert total catch (no discard survival)
  catch(stk_oem)[, ac(yrs_hist)]    <- catch(stk_data_input)[, ac(yrs_hist)]
  catch.n(stk_oem)[, ac(yrs_hist)]  <- catch.n(stk_data_input)[, ac(yrs_hist)]
  catch.wt(stk_oem)[, ac(yrs_hist)] <- catch.wt(stk_data_input)[, ac(yrs_hist)]
  landings(stk_oem)[, ac(yrs_hist)]    <- landings(stk_data_input)[, ac(yrs_hist)]
  landings.n(stk_oem)[, ac(yrs_hist)]  <- landings.n(stk_data_input)[, ac(yrs_hist)]
  landings.wt(stk_oem)[, ac(yrs_hist)] <- landings.wt(stk_data_input)[, ac(yrs_hist)]
  discards(stk_oem)[, ac(yrs_hist)]    <- discards(stk_data_input)[, ac(yrs_hist)]
  discards.n(stk_oem)[, ac(yrs_hist)]  <- discards.n(stk_data_input)[, ac(yrs_hist)]
  discards.wt(stk_oem)[, ac(yrs_hist)] <- discards.wt(stk_data_input)[, ac(yrs_hist)]

  ### account for discard survival (historical years and intermediate year)
  discards.n(stk_oem)[, ac(yrs_hist)] <- 
    discards.n(stk_oem)[, ac(yrs_hist)] * (1 - disc_survival_MP)
  # "catch.wt" "catch.n"  "catch"    "landings" "discards"
  catch_tmp <- computeCatch(stk_oem[, ac(yrs_hist)], slot = "all")
  catch.wt(stk_oem)[, ac(yrs_hist)] <- catch_tmp$catch.wt
  catch.n(stk_oem)[, ac(yrs_hist)] <- catch_tmp$catch.n
  catch(stk_oem)[, ac(yrs_hist)] <- catch_tmp$catch
  landings(stk_oem)[, ac(yrs_hist)] <- catch_tmp$landings
  discards(stk_oem)[, ac(yrs_hist)] <- catch_tmp$discards
  
  ### catch weights for projection years
  catch.wt(stk_oem)[, ac(proj_yrs)] <- 
    yearMeans(catch.wt(stk_oem)[, ac(sample_yrs)])
  landings.wt(stk_oem)[, ac(proj_yrs)] <- 
    yearMeans(landings.wt(stk_oem)[, ac(sample_yrs)])
  discards.wt(stk_oem)[, ac(proj_yrs)] <- 
    yearMeans(discards.wt(stk_oem)[, ac(sample_yrs)])
  
  ### ---------------------------------------------------------------------- ###
  ### catch noise ####
  ### take estimates from sam: uncertainty$catch_sd is "logSdLogObs"
  ### assume catch observed by SAM in projection is log-normally distributed
  ### around operating model catch
  if (isTRUE(catch_oem_error)) {
    message("including catch observation error")
    ### create noise for catch
    set.seed(5)
    catch_res <- catch.n(stk_fwd) %=% 0 ### template FLQuant
    catch_res[] <- stats::rnorm(n = length(catch_res), mean = 0, 
                                sd = uncertainty$catch_sd)
    ### the catch_res values are on a normal scale,
    ### exponentiate to get log-normal 
    catch_res <- exp(catch_res)
    ### catch_res is a factor by which the numbers at age are multiplied
    ### for historical period, pass on real observed catch
    ### -> remove deviation
    ### -> includes difference between OM and MP discard survival
    catch_res[, ac(yrs_hist)] <- 
      window(catch.n(stk_oem), end = yr_data) / 
      window(catch.n(stk_fwd), end = yr_data)
    
    ### account for discard survival: OM vs MP in projection period
    ### correction factor discards
    ### (historical data is already corrected for discard survival)
    disc_res <- catch_res %=% 1
    disc_res[, ac(yrs_proj)] <- 1/(1 - disc_survival_OM) * (1 - disc_survival_MP)
    
    ### update intermediate year
    if (isTRUE(int_yr_add)) {
      ### get landings
      landings.n(stk_oem)[, ac(int_yr_yr)] <- 
        landings.n(stk_fwd)[, ac(int_yr_yr)] * catch_res[, ac(int_yr_yr)]
      ### get discards and correct for assumed survival
      discards.n(stk_oem)[, ac(int_yr_yr)] <-
        discards.n(stk_fwd)[, ac(int_yr_yr)] * catch_res[, ac(int_yr_yr)] *
        disc_res[, ac(int_yr_yr)]
      ### update total catch and weights
      catch_tmp <- computeCatch(stk_oem[, ac(int_yr_yr)], slot = "all")
      catch.wt(stk_oem)[, ac(int_yr_yr)] <- catch_tmp$catch.wt
      catch.n(stk_oem)[, ac(int_yr_yr)] <- catch_tmp$catch.n
      catch(stk_oem)[, ac(int_yr_yr)] <- catch_tmp$catch
      landings(stk_oem)[, ac(int_yr_yr)] <- catch_tmp$landings
      discards(stk_oem)[, ac(int_yr_yr)] <- catch_tmp$discards
      
      ### combine catch residuals
      catch_res <- FLQuants(catch_res = catch_res,
                            disc_res = disc_res)
      
    }

  } else {
    message("NOT including catch observation error")
    catch_res <- FLQuants(catch_res = catch.n(stk_fwd) %=% 1,
                          disc_res = catch.n(stk_fwd) %=% 1)
  }
  
  ### ---------------------------------------------------------------------- ###
  ### indices ####
  message("creating OM indices")
  ### use real FLIndices object as template (use all)
  idx <- idx_data
  ### extend for simulation period
  idx <- window(idx, end = yr_data + n_years_new)
  ### add iterations
  idx <- lapply(idx, propagate, n)
  ### extract some dimension names
  idx_yrs <- lapply(idx, function(x) as.numeric(dimnames(x)$year))
  idx_yrs_hist <- lapply(idx_yrs, function(x) setdiff(x, yrs_proj))
  idx_ages <- lapply(idx, function(x) dimnames(x)$age)
  ### set catchability for projection
  for (idx_i in seq_along(idx)) {
    index.q(idx[[idx_i]])[] <- uncertainty$survey_catchability[[idx_i]]
  }
  ### index weights
  for (idx_i in seq_along(idx)) {
    ### use weights from index - resample
    ### (same approach as for catch and stock weights)
    ### observations: average weight
    catch.wt(idx[[idx_i]])[, ac(proj_yrs)] <- 
      yearMeans(catch.wt(idx[[idx_i]])[, ac(sample_yrs)])
  }
  ### create copy of index with original values
  idx_raw <-  lapply(idx ,index)
  ### calculate index numbers
  idx <- calc_survey(stk = stk_fwd, idx = idx, use_q = TRUE, use_time = TRUE, 
                     use_wt = FALSE)
  ### create deviances for indices
  ### first, get template
  idx_dev <- lapply(idx, index)
  ### create random noise based on sd
  set.seed(4)
  for (idx_i in seq_along(idx_dev)) {
    ### insert sd
    idx_dev[[idx_i]][] <- uncertainty$survey_sd[[idx_i]]
    ### noise
    idx_dev[[idx_i]][] <- stats::rnorm(n = length(idx_dev[[idx_i]]),
                                       mean = 0, sd = idx_dev[[idx_i]])
    ### exponentiate to get from normal to log-normal scale
    idx_dev[[idx_i]] <- exp(idx_dev[[idx_i]])
  }
  idx_dev_raw <- idx_dev
  ### modify residuals for historical period so that index values passed to 
  ### stock assessment are the ones observed in reality
  for (idx_i in seq_along(idx_dev)) {
    idx_dev[[idx_i]][, ac(idx_yrs_hist[[idx_i]])] <-
      idx_raw[[idx_i]][, ac(idx_yrs_hist[[idx_i]])] /
      index(idx[[idx_i]])[, ac(idx_yrs_hist[[idx_i]])]
  }

  ### add template for biomass index
  if (!isFALSE(idxB)) {
    message("adding biomass index template")
    if (is.numeric(idxB)) idxB <- names(idx)[idxB]
    idxB_template <- quantSums(idx[[idxB]]@catch.wt * 
                                 idx[[idxB]]@index) %=% NA_real_
    idx <- FLIndices(c(idx, idxB = FLIndex(index = idxB_template)))
    idx_dev[["idxB"]] <- idxB_template
  }
  
  ### ---------------------------------------------------------------------- ###
  ### length index ####
  if (isTRUE(idxL)) {
    message("adding length index")
    if (is.null(ALK_yrs)) {
      ALK_yrs <- sort(unique(ALKs$year))
    } else {
      ALKs <- ALKs %>%
        filter(year %in% ALK_yrs)
    }
    ALKs <- ALKs %>%
      arrange(year, age, length)
    ### randomly select ALK years
    if (is.null(ALK_yrs_sample)) ALK_yrs_sample <- sort(unique(ALKs$year))
    set.seed(89)
    alk_samples <- catch(stk_fwd) %=% NA_real_
    alk_samples[] <- sample(x = ALK_yrs_sample, size = length(yrs_mse) * n, 
                            replace = TRUE)
    ### use existing ALKs for historical years
    alk_samples[, ac(ALK_yrs)] <- ALK_yrs
    ### pre-populate index
    set.seed(91)
    data_yrs <- range(stk_fwd)[["minyear"]]:yr_data
    ### match ALK year with data year
    lmean <- full_join(
      ### use observed catch
      x = as.data.frame(catch.n(stk_fwd)[, ac(data_yrs)]) %>%
        select(year, age, iter, data) %>%
        mutate(data = ifelse(data < 0, 0, data)) %>% ### shouldn't happen...
        rename("caa" = "data") %>%
        mutate(iter = as.numeric(as.character(iter))) %>%
        mutate(caa = caa + .Machine$double.eps), ### avoid 0s
      y = as.data.frame(alk_samples[, ac(data_yrs)]) %>%
        select(year, iter, data) %>%
        rename("alk_year" = "data") %>%
        mutate(iter = as.numeric(as.character(iter))), 
      by = c("year", "iter")) %>%
      ### merge with ALKs
      left_join(ALKs %>% rename("alk_year" = "year"),
                by = c("age", "alk_year"),
                relationship = "many-to-many") %>%
      ### calculate numbers at length
      mutate(cal = caa * freq) %>%
      ### keep only numbers where length >= Lc
      filter(length >= refpts$Lc) %>% 
      ### mean catch length above Lc
      group_by(year, iter) %>%
      summarise(data = mean(sample(x = length, prob = cal, 
                                   size = length_samples, replace = TRUE)),
                .groups = "keep") %>%
      arrange(as.numeric(as.character(iter)))
    ### convert into FLQuant
    idxL <-  window(as.FLQuant(lmean), end = dims(stk_fwd)$maxyear)
    ### add to index
    idx <- FLIndices(c(idx, idxL = FLIndex(index = idxL)))
    idx_dev[["idxL"]] <- idxL %=% 1
    idx_dev[["alk_yrs"]] <- alk_samples
  }
  
  ### ------------------------------------------------------------------------ ###
  ### PA buffer for 2 over 3 rule ####
  ### SPiCT performance based on 
  ### Fischer et al. 2021 https://doi.org/10.1093/icesjms/fsab018
  ### index deviation
  if (isTRUE(PA_status)) {
    message("adding template for PA status")
    PA_status_dev <- FLQuant(NA, dimnames = list(age = c("positive", "negative"), 
                                                 year = dimnames(stk_fwd)$year, 
                                                 iter = dimnames(stk_fwd)$iter))
    set.seed(1)
    PA_status_dev["positive"] <- rbinom(n = PA_status_dev["positive"], 
                                        size = 1, prob = 0.9886215)
    set.seed(2)
    PA_status_dev["negative"] <- rbinom(n = PA_status_dev["negative"], 
                                        size = 1, prob = 1 - 0.4216946)
    ### PA status index template
    PA_status_template <- FLIndex(index = ssb(stk_fwd) %=% NA_integer_)
    ### add to index object
    idx <- FLIndices(c(idx, PA_status = PA_status_template))
    idx_dev[["PA_status"]] <- PA_status_dev
  }
  
  ### ---------------------------------------------------------------------- ###
  ### format reference points ####
  refpts <- FLPar(refpts, unit = "")
  
  ### ---------------------------------------------------------------------- ###
  ### save ####
  if (isTRUE(save)) {
    
    ### path
    input_path <- paste0("input/", stock_id, "/", OM, "/", n, "_", n_years, "/")
    dir.create(input_path, recursive = TRUE)
    
    ### SAM model fit
    saveRDS(fit, file = paste0(input_path, "SAM_fit.rds"))
    ### stock
    saveRDS(stk_fwd, file = paste0(input_path, "stk.rds"))
    ### stock recruitment
    saveRDS(sr, file = paste0(input_path, "sr.rds"))
    ### surveys
    saveRDS(idx, file = paste0(input_path, "idx.rds"))
    saveRDS(idx_dev, file = paste0(input_path, "idx_dev.rds"))
    saveRDS(idx_dev_raw, file = paste0(input_path, "idx_dev_raw.rds"))
    ### catch noise
    saveRDS(catch_res, file = paste0(input_path, "catch_res.rds"))
    ### process error
    saveRDS(proc_res, file = paste0(input_path, "proc_res.rds"))
    ### observed stock
    saveRDS(stk_oem, file = paste0(input_path, "stk_oem.rds"))
    ### sam initial parameters
    saveRDS(pars_ini, file = paste0(input_path, "SAM_initial.rds"))
    ### sam configuration
    saveRDS(SAM_conf, file = paste0(input_path, "SAM_conf.rds"))
    ### reference values
    saveRDS(refpts, file = paste0(input_path, "refpts_mse.rds"))
    ### age-length keys
    saveRDS(ALKs, file = paste0(input_path, "ALKs.rds"))
    ### SAM uncertainty
    saveRDS(uncertainty, file = paste0(input_path, "SAM_uncertainty.rds"))
  }
  if (isTRUE(return)) {
    return(list(stk_fwd = stk_fwd, sr = sr, idx = idx, idx_dev = idx_dev,
                catch_res = catch_res, proc_res = proc_res, stk_oem = stk_oem,
                pars_ini = pars_ini, SAM_conf = SAM_conf, refpts = refpts,
                ALKs = ALKs))
  }
  
}

### ------------------------------------------------------------------------ ###
### create input for mp() ####
### ------------------------------------------------------------------------ ###
### this function loads the elements required for running mse::mp(),
### adapts them if necessary (dimensions), sets the MP and 
### creates the input object for mp()

input_mp <- function(stock_id = "ple.27.7e", OM = "baseline", n_iter = 1000,
                     n_yrs = 100, yr_start = 2021, iy = yr_start - 1,
                     n_blocks = FALSE, parallel = n_blocks, seed = 1, 
                     cut_hist = TRUE, MP = "chr",
                     hr_years = NULL,
                     migration = NULL,
                     disc_survival = 0, 
                     ### recruitment
                     rec_failure = FALSE, ### FALSE 
                     rec_failure_yrs = 2025:2029,
                     rec_failure_reduction = 0.9,
                     rec_alternative = FALSE, ### FALSE or multiplier
                     ### observations
                     use_catch_residuals = TRUE,
                     use_catch_residuals_disc = TRUE,
                     oem_catch_bias = FALSE, oem_catch_bias_level = NULL,
                     overcatch = FALSE,
                     use_age_idcs = NULL, biomass_index = NULL,
                     idx_timing = NULL, catch_timing = NULL,
                     ### implementation error
                     use_iem = FALSE, iem_bias = NULL,
                     ### SAM forecast options
                     fwd_yrs_rec_start = NULL,
                     fwd_splitLD = NULL,
                     fwd_yrs_average = NULL,
                     fwd_yrs_sel = NULL,
                     fwd_trgt = NULL, fwd_yrs = NULL
                     ) {
  
  ### overcatch - higher catch in OM but MP doesn't know
  if (!isFALSE(overcatch)) {
    use_iem <- TRUE
    iem_bias <- 1 + overcatch
    oem_catch_bias <- TRUE
    oem_catch_bias_level <- 1/iem_bias
  }
  
  ### load data and adapt dimensions - for all OM(s)
  yr_end <- yr_start + n_yrs - 1
  OM_list <- foreach(OM_i = OM) %do% {
    
    ### path to input objects
    path_input <- paste0("input/", stock_id, "/", OM_i, "/", 1000, "_100/")
    
    ### load objects
    ### use full dimensions (100 years, 1000 iterations) - reduced later
    stk_fwd <- readRDS(paste0(path_input, "stk.rds"))
    sr <- readRDS(paste0(path_input, "sr.rds"))
    idx <- readRDS(paste0(path_input, "idx.rds"))
    idx_dev <- readRDS(paste0(path_input, "idx_dev.rds"))
    catch_res <- readRDS(paste0(path_input, "catch_res.rds"))
    proc_res <- readRDS(paste0(path_input, "proc_res.rds"))
    stk_oem <- readRDS(paste0(path_input, "stk_oem.rds"))
    SAM_pars_ini <- readRDS(paste0(path_input, "SAM_initial.rds"))
    SAM_conf <- readRDS(paste0(path_input, "SAM_conf.rds"))
    ALKs <- readRDS(paste0(path_input, "ALKs.rds"))
    refpts_mse <- readRDS(paste0(path_input, "refpts_mse.rds"))
    ### reduce dimensions, if requested
    if (isTRUE(n_yrs < 100)) {
      ### OM stock
      stk_fwd <- window(stk_fwd, end = yr_end)
      ### OEM stock
      stk_oem <- window(stk_oem, end = yr_end)
      ### stock-recruitment model
      sr <- window(sr, end = yr_end)
      ### index
      idx <- window(idx, end = yr_end)
      ### residuals
      idx_dev <- window(idx_dev, end = yr_end)
      catch_res <- window(catch_res, end = yr_end)
      proc_res <- window(proc_res, end = yr_end)
    }
    if (isTRUE(n_iter < 1000)) {
      ### OM stock
      stk_fwd <- FLCore::iter(stk_fwd, seq(n_iter))
      ### OEM stock
      stk_oem <- FLCore::iter(stk_oem, seq(n_iter))
      ### stock-recruitment model 
      sr <- FLCore::iter(sr, seq(n_iter))
      ### index
      idx <- FLCore::iter(idx, seq(n_iter))
      ### residuals
      idx_dev <- FLCore::iter(idx_dev, seq(n_iter))
      catch_res <- FLCore::iter(catch_res, seq(n_iter))
      proc_res <- FLCore::iter(proc_res, seq(n_iter))
      ### reference points
      if (isTRUE(n_iter < dims(refpts_mse)$iter))
        refpts_mse <- iter(refpts_mse, seq(n_iter))
    }
    
    return(list(stk_fwd = stk_fwd, sr = sr, idx = idx, idx_dev = idx_dev,
                catch_res = catch_res, proc_res = proc_res, stk_oem = stk_oem,
                SAM_pars_ini = SAM_pars_ini, SAM_conf = SAM_conf, ALKs = ALKs,
                refpts_mse = refpts_mse))
  }
  
  ### return objects or combine them
  if (identical(length(OM), 1L)) {
    
    stk_fwd <- OM_list[[1]]$stk_fwd
    sr <- OM_list[[1]]$sr
    idx <- OM_list[[1]]$idx
    idx_dev <- OM_list[[1]]$idx_dev
    catch_res <- OM_list[[1]]$catch_res
    proc_res <- OM_list[[1]]$proc_res
    stk_oem <- OM_list[[1]]$stk_oem
    SAM_pars_ini <- OM_list[[1]]$SAM_pars_ini
    SAM_conf <- OM_list[[1]]$SAM_conf
    ALKs <- OM_list[[1]]$ALKs
    refpts_mse <- OM_list[[1]]$refpts_mse
    
  } else {
    
    ### FLR objects -> FLCore::combine
    stk_fwd <- Reduce(FLCore::combine, lapply(OM_list, "[[", "stk_fwd"))
    sr <- Reduce(FLCore::combine, lapply(OM_list, "[[", "sr"))
    idx <- Reduce(FLCore::combine, lapply(OM_list, "[[", "idx"))
    idx_dev <- Reduce(FLCore::combine, lapply(OM_list, "[[", "idx_dev"))
    catch_res <- Reduce(FLCore::combine, lapply(OM_list, "[[", "catch_res"))
    proc_res <- Reduce(FLCore::combine, lapply(OM_list, "[[", "proc_res"))
    stk_oem <- Reduce(FLCore::combine, lapply(OM_list, "[[", "stk_oem"))
    refpts_mse <- Reduce(FLCore::combine, lapply(OM_list, "[[", "refpts_mse"))
    ### SAM -> impossible to combine, use first
    SAM_pars_ini <- OM_list[[1]]$SAM_pars_ini
    SAM_conf <- OM_list[[1]]$SAM_conf
    ### ALK -> identical for all OMs, use first
    ALKs <- OM_list[[1]]$ALKs
    
  }
  
  ### ---------------------------------------------------------------------- ###
  ### alternative recruitment? ####
  ### ---------------------------------------------------------------------- ###
  ### recruitment failure?
  if (isTRUE(rec_failure)) {
    
    residuals(sr)[, ac(rec_failure_yrs)] <- 
      residuals(sr)[, ac(rec_failure_yrs)] * (1 - rec_failure_reduction)
    
  }
  
  ### lower/higher recruitment?
  if (!isFALSE(rec_alternative)) {
    
    residuals(sr) <- residuals(sr) * rec_alternative
    
  }
  
  ### ---------------------------------------------------------------------- ###
  ### generic arguments ####
  args <- list(fy = yr_end, ### final simulation year
               y0 = dims(stk_fwd)$minyear, ### first data year
               data_lag = 0, ### make ay catch available
               management_lag = 0, ### save advice in tracking's ay
               iy = iy, ### first simulation (intermediate) year
               nsqy = 3, ### not used, but has to provided
               seed = seed ### random number seed before starting MSE
  )
  if (identical(MP, "ICES_SAM")) {
    args$data_lag <- 1
    args$managment_lag <- 1
  }
  
  ### ---------------------------------------------------------------------- ###
  ### reference values ####
  # refpts_mse <- FLPar(refpts_mse, iter = n_iter)
  
  ### ---------------------------------------------------------------------- ###
  ### Operating model (OM) ####
  om <- FLom(stock = stk_fwd, ### stock 
             sr = sr, ### stock recruitment and precompiled residuals
             projection = mseCtrl(method = fwd_attr, 
                                  args = list(maxF = 5,
                                              ### process noise on stock.n
                                              proc_res = proc_res,
                                              disc_survival = disc_survival
                                  ))
  )
  
  ### ---------------------------------------------------------------------- ###
  ### migration ####
  if (!is.null(migration)) {
    if (isTRUE(length(migration) == 1)) {
      migr_fct <- seq(from = 1, to = migration, length.out = n_yrs + 1)
      migr_fct <- migr_fct[-1]/migr_fct[-length(migr_fct)]
      #prod(migr_fct)
    } else {
      migr_fct <- migration
    }
    migr_qnt <- ssb(stk_fwd) %=% 1
    migr_qnt[, ac(yr_start:dims(migr_qnt)$maxyear)] <- migr_fct
    ### store in sr ssb slot
    om@sr@ssb <- migr_qnt
    om@projection@args$migration = "ssb"
  }
  
  ### ---------------------------------------------------------------------- ###
  ### Observation (error) model OEM ####
  if (identical(stock_id, "ple.27.7e")) {
    if (is.null(use_age_idcs)) use_age_idcs <- c("Q1SWBeam", "UK-FSP")
    if (is.null(biomass_index)) biomass_index <- "UK-FSP"
    if (is.null(idx_timing)) idx_timing <- c(-1, -1)
    if (is.null(catch_timing)) catch_timing <- -1
  }
  
  ### bias in catch observations?
  if (isTRUE(oem_catch_bias)) {
    catch_res$catch_res[] <- catch_res$catch_res * oem_catch_bias_level
  }
  
  ### default oem for rfb rule
  oem <- FLoem(method = obs_generic,
               observations = list(
                 stk = stk_oem, 
                 idx = idx), 
               deviances = list(
                 stk = catch_res, 
                 idx = idx_dev),
               args = list(use_catch_residuals = use_catch_residuals, 
                           use_catch_residuals_disc = use_catch_residuals_disc,
                           use_idx_residuals = TRUE,
                           use_stk_oem = TRUE,
                           use_wt = TRUE,
                           alks = as.data.frame(ALKs),
                           use_age_idcs = use_age_idcs,
                           biomass_index = biomass_index,
                           length_idx = TRUE,
                           Lc = unique(c(refpts_mse["Lc"])),
                           lngth_samples = 2000))
  
  ### 2 over 3 rule: biomass index and PA status relative to OM + error
  if (isTRUE(MP == "2over3")) {
    oem@args$length_idx <- FALSE ### no length index
    oem@args$PA_status <- TRUE 
    oem@args$PA_status_dev <- TRUE
    oem@args$PA_Bmsy <- unique(c(refpts_mse["Bmsy"])) ### real MSY from OM
    oem@args$PA_Fmsy <- unique(c(refpts_mse["Fmsy"]))
  ### 2 over 3 based on XSA 
  } else if (isTRUE(MP == "2over3_XSA")) {
    oem@args$length_idx <- FALSE ### no length index
    oem@args$PA_status <- TRUE 
    oem@args$PA_status_dev <- TRUE
  ### ICES category 1 with SAM
  } else if (isTRUE(MP == "ICES_SAM")) {
    oem@observations$idx <- oem@observations$idx[use_age_idcs] ### age indices only
    oem@deviances$idx <- oem@deviances$idx[use_age_idcs]
    oem@args <- list(cut_idx = TRUE, idx_timing = idx_timing,
                     catch_timing = catch_timing, use_catch_residuals = TRUE,
                     use_idx_residuals = TRUE, use_stk_oem = TRUE)
  ### harvest rate based on biomass index
  } else if (isTRUE(MP == "hr")) {
    ### remove redundant indices and arguments
    oem@observations$idx <- oem@observations$idx[c(use_age_idcs, "idxB")]
    oem@deviances$idx <- oem@deviances$idx[c(use_age_idcs, "idxB")]
    oem@args$alks <- NULL
    oem@args$length_idx <- FALSE
    oem@args$Lc <- NULL
    oem@args$lngth_samples <- NULL
  } else if (isTRUE(MP == "constF")) {
    oem <- FLoem(method = oem_dummy,
                 observations = list(stk = FLQuant(0),
                                     idx = FLQuant()),
                 deviances = list(stk = FLQuant(0),
                                  idx = FLQuant()))
  }
  
  ### ---------------------------------------------------------------------- ###
  ### Management procedure MP ####
  
  if (isTRUE(MP == "rfb")) {
    idxB <- quantSums(index(idx[[biomass_index]]) *
                        idx_dev[[biomass_index]] * 
                        catch.wt(idx[[biomass_index]]))
    ### I_loss
    ### (I_trigger defined inside estimator)
    I_loss = apply(idxB, 6, min, na.rm = TRUE)
    ctrl <- mpCtrl(list(
      est = mseCtrl(method = est_comps,
                    args = list(comp_r = TRUE, comp_f = TRUE, comp_b = TRUE,
                                comp_c = TRUE, comp_m = 1,
                                idxB_lag = 1, idxB_range_1 = 2, idxB_range_2 = 3,
                                idxB_range_3 = 1,
                                catch_lag = 0, ### 0 to mimic advice
                                catch_range = 1,
                                Lref = unique(c(refpts_mse["Lref"])), 
                                I_loss = c(I_loss),
                                comp_b_multiplier = 1.4,
                                idxL_lag = 1, idxL_range = 1)),
      phcr = mseCtrl(method = phcr_comps,
                     args = list(exp_r = 1, exp_f = 1, exp_b = 1)),
      hcr = mseCtrl(method = hcr_comps,
                    args = list(interval = 2)),
      isys = mseCtrl(method = is_comps,
                     args = list(interval = 2, 
                                 upper_constraint = 1.2, lower_constraint = 0.7, 
                                 cap_below_b = FALSE))
    ))
  } else if (isTRUE(MP == "hr")) {
    idxB <- quantSums(index(idx[[biomass_index]]) *
                        idx_dev[[biomass_index]] * 
                        catch.wt(idx[[biomass_index]]))
    idxB_yrs <- dimnames(idxB)$year[which(!is.na(iterMeans(idxB)))]
    ### get observed catch - mimic OEM function (obs_generic)
    if (isTRUE(use_catch_residuals_disc)) {
      stk_tmp <- stock(om)
      landings.n(stk_tmp) <- landings.n(stock(om)) * oem@deviances$stk$catch_res
      discards.n(stk_tmp) <- discards.n(stock(om)) * 
        oem@deviances$stk$catch_res * oem@deviances$stk$disc_res
      catch(stk_tmp) <- computeCatch(stk_tmp, slot = "all")
      idxC <- catch(stk_tmp)
    } else {
      idxC <- quantSums(catch.n(stk_fwd) * catch.wt(stk_fwd) *
                          oem@deviances$stk$catch_res)
    }
    ### I_loss
    ### (I_trigger defined inside estimator)
    I_loss = apply(idxB, 6, min, na.rm = TRUE)
    ### define target harvest rate through reference years
    hr_values <- idxC[, ac(idxB_yrs)]/idxB[, ac(idxB_yrs)]
    if (is.null(hr_years)) {
      if (identical(stock_id, "ple.27.7e")) {
        hr_years <- 2003:2023 ### use all historical years (excl. intermediate)
      } else {
        hr_years <- NULL
      }
    }
    ### WKLIFE X: target is mean harvest of target years * 0.5
    ### here: remove 0.5 to get multiplier relative to target
    hr_target <- yearMeans(hr_values[, ac(hr_years)]) #* 0.5
    
    ctrl <- mpCtrl(list(
      est = mseCtrl(method = est_comps,
                    args = list(comp_r = FALSE, comp_f = FALSE, comp_b = TRUE,
                                comp_c = FALSE, comp_m = 1, 
                                comp_i = TRUE, comp_hr = c(hr_target),
                                idxB_lag = 1, idxB_range_3 = 1,
                                I_loss = c(I_loss),
                                comp_b_multiplier = 1.4)),
      phcr = mseCtrl(method = phcr_comps,
                     args = list(exp_r = 1, exp_f = 1, exp_b = 1)),
      hcr = mseCtrl(method = hcr_comps,
                    args = list(interval = 1)),
      isys = mseCtrl(method = is_comps,
                     args = list(interval = 1, 
                                 upper_constraint = 1.2, lower_constraint = 0.7,
                                 cap_below_b = FALSE))
    ))
  } else if (isTRUE(MP == "2over3")) {
    ctrl <- mpCtrl(list(
      est = mseCtrl(method = est_comps,
                    args = list(comp_r = TRUE, comp_f = FALSE, comp_b = FALSE,
                                comp_c = TRUE, comp_m = 1, 
                                idxB_lag = 1, idxB_range_1 = 2, idxB_range_2 = 3,
                                catch_lag = 0, ### 0 to mimic advice
                                catch_range = 1, 
                                pa_buffer = TRUE, 
                                pa_size = 0.8, pa_duration = 3)),
      phcr = mseCtrl(method = phcr_comps),
      hcr = mseCtrl(method = hcr_comps,
                    args = list(interval = 2)),
      isys = mseCtrl(method = is_comps,
                     args = list(interval = 2, 
                                 upper_constraint = 1.2, lower_constraint = 0.8, 
                                 cap_below_b = TRUE))))
  } else if (isTRUE(MP == "2over3_XSA")) {
    FLXSA_control <- FLXSA.control(fse = 1.0, rage = 0, qage = 6, 
                                   shk.n = FALSE, 
                                   shk.ages = 3, shk.yrs = 3, 
                                   min.nse = 0.3, 
                                   tspower = 0, tsrange = 100,
                                   maxit = 100)
    ctrl <- mpCtrl(list(
      est = mseCtrl(method = est_comps,
        args = list(comp_r = TRUE, comp_f = FALSE, comp_b = FALSE,
                    comp_c = TRUE, comp_m = 1, pa_buffer = TRUE,
                    idxB_lag = 1, 
                    idxB_range_1 = 2, idxB_range_2 = 3,
                    catch_lag = 0, ### 0 to mimic advice
                    catch_range = 1,
                    FLXSA = TRUE,
                    FLXSA_control = FLXSA_control,
                    FLXSA.control = NULL,
                    FLXSA_landings = TRUE, ### landings only?
                    FLXSA_idcs = c("Q1SWBeam", "FSP-7e"),
                    FLXSA_stf = TRUE,
                    ### from WGCSE
                    FLXSA_Btrigger = unique(c(refpts_mse["ICES_Btrigger"])), 
                    FLXSA_Ftrigger = unique(c(refpts_mse["ICES_Fmsy"]))
                    )),
      phcr = mseCtrl(method = phcr_comps),
      hcr = mseCtrl(method = hcr_comps,
                    args = list(interval = 1)), ### annual
      isys = mseCtrl(method = is_comps,
                     args = list(interval = 2, ### annual
                                 upper_constraint = 1.2, lower_constraint = 0.8, 
                                 cap_below_b = TRUE))))
  } else if (isTRUE(MP == "ICES_SAM")) {
    if (stock_id %in% c("ple.27.7e")) {
      ### some specifications for short term forecast with SAM
      if (identical(stock_id, "ple.27.7e")) {
        if (is.null(fwd_yrs_rec_start)) fwd_yrs_rec_start <- 1980
        if (is.null(fwd_splitLD)) fwd_splitLD <- TRUE
        if (is.null(fwd_yrs_average)) fwd_yrs_average <- -4:0
        if (is.null(fwd_yrs_sel)) fwd_yrs_sel <- -4:0
        if (is.null(fwd_trgt)) fwd_trgt <- c("fsq", "fsq", "fsq")
        if (is.null(fwd_yrs)) fwd_yrs <- 2
      }
      SAM_stf_def <- list(fwd_yrs_rec_start = fwd_yrs_rec_start,
                          fwd_splitLD = fwd_splitLD,
                          fwd_yrs_average = fwd_yrs_average,
                          fwd_yrs_sel = fwd_yrs_sel)
      ctrl <- mpCtrl(list(
        est = mseCtrl(method = SAM_wrapper,
                      args = c(### short term forecast specifications
                        forecast = TRUE, 
                        fwd_trgt = list(fwd_trgt), fwd_yrs = fwd_yrs, 
                        SAM_stf_def, ### without list structure
                        newtonsteps = 0, rel.tol = 0.001,
                        par_ini = list(SAM_pars_ini),
                        track_ini = TRUE, 
                        conf = list(SAM_conf)
                      )),
        phcr = mseCtrl(method = phcr_WKNSMSE,
                       args = list(
                         Btrigger = unique(c(refpts_mse["EqSim_Btrigger"])), 
                         Ftrgt = unique(c(refpts_mse["EqSim_Fmsy"])), 
                         Blim = unique(c(refpts_mse["EqSim_Blim"])))),
        hcr = mseCtrl(method = hcr_WKNSME, args = list(option = "A")),
        isys = mseCtrl(method = is_WKNSMSE, 
                       args = c(hcrpars = list(
                         Btrigger = unique(c(refpts_mse["EqSim_Btrigger"])), 
                         Ftrgt = unique(c(refpts_mse["EqSim_Fmsy"])), 
                         Blim = unique(c(refpts_mse["EqSim_Blim"]))),
                         fwd_trgt = list(c(fwd_trgt, "hcr")), 
                         fwd_yrs = fwd_yrs + 1, SAM_stf_def
                       ))))
    } 
  } else if (isTRUE(MP == "constF")) {
    ctrl <- mpCtrl(list(est = mseCtrl(method = perfect.sa),
                        hcr = mseCtrl(method = fixedF_hcr,
                                      args = list(ftrg = 0))))
  }
  
  ### ---------------------------------------------------------------------- ###
  ### IEM - implementation error model ####
  
  if (isTRUE(use_iem)) {
    iem_dev <- catch(stk_fwd) %=% 1
    iem_dev[] <- iem_bias
    iem <- FLiem(method = iem_comps,
                 args = list(use_dev = TRUE,
                             iem_dev = iem_dev))
  } else {
    iem <- NULL
  }
  
  
  ### ---------------------------------------------------------------------- ###
  ### additional tracking metrics ####
  tracking <- c("comp_c", "comp_i", "comp_r", "comp_f", "comp_b", "comp_hr",
                "multiplier", "exp_r", "exp_f", "exp_b")
  if (isTRUE(MP == "ICES_SAM")) {
    tracking <- c("BB_return", "BB_bank_use", "BB_bank", "BB_borrow")
  }
  
  ### ---------------------------------------------------------------------- ###
  ### create input object ####
  
  input <- list(om = om, oem = oem, ctrl = ctrl, iem = iem,
                args = args, tracking = tracking, parallel = parallel)
  #, refpts = refpts_mse, cut_hist = cut_hist
  
  return(input)
  
}

### ------------------------------------------------------------------------ ###
### function for estimating MSY reference values ####
### ------------------------------------------------------------------------ ###
# res <- est_MSY(n_iter = 10, n_blocks = 1, vals_ini = c(0, 0.5, 1), tol = 0.1)
est_MSY <- function(stock_id = "ple.27.7e", OM = "baseline",
                    yr_start = 2025, n_blocks = 1, n_iter = 1000,
                    vals_ini = seq(0, 1, 0.1),
                    lower = 0, upper = 0.3, tol = 0.001,
                    plot = TRUE, x_label = "F (ages 3-6)",
                    save = TRUE) {
  #browser()
  path <- path_input <- paste0("input/", stock_id, "/", OM, "/", n_iter, 
                               "_100/")
  
  ### load mp input
  input <- input_mp(n_iter = n_iter, stock_id = stock_id, OM = OM,
                    yr_start = yr_start, MP = "constF", n_blocks = n_blocks)
  input$verbose <- FALSE ### quiet
  
  ### check if some results already exist
  if (isTRUE(save)) {
    if (isTRUE(file.exists(paste0(path, "MSY_trace.rds")))) {
      res_trace_ini <- readRDS(paste0(path, "MSY_trace.rds"))
    } else {
      res_trace_ini <- list()
    }
  }
  ### create object in new environment for storing results
  trace_env <- new.env()
  assign(x = "res_trace", value = res_trace_ini, envir = trace_env)
  
  ### define function for running projection and returning stats
  mp_catch <- function(input, Ftrgt, minimise = FALSE) {#browser()
    res_trace_i <- get("res_trace", envir = trace_env)
    ### if run already exists, do not run again
    if (isTRUE(Ftrgt %in% sapply(res_trace_i, function(x) x$Ftrgt))) {
      res_i <- res_trace_i[[which(Ftrgt == sapply(res_trace_i, 
                                                  function(x) x$Ftrgt))[[1]]]]
      catch_i <- res_i$catch
      ssb_i <- res_i$ssb
      tsb_i <- res_i$tsb
      rec_i <- res_i$rec
    } else {
      ### run projection
      input$ctrl$hcr@args$ftrg <- Ftrgt
      res_i <- do.call(mp, input)
      catch_i <- median(tail(catch(res_i@om@stock), 10), na.rm = TRUE)
      ssb_i <- median(tail(ssb(res_i@om@stock), 10), na.rm = TRUE)
      tsb_i <- median(tail(tsb(res_i@om@stock), 10), na.rm = TRUE)
      rec_i <- median(tail(rec(res_i@om@stock), 10), na.rm = TRUE)
    }
    ### print results of current run
    cat(paste0("Ftrgt=", Ftrgt, "; C=", catch_i, "; SSB=", ssb_i, "; R=", rec_i,
               "\n"))
    ### save results in res_trace
    res_add <- list(list(Ftrgt = Ftrgt, catch = catch_i,
                         ssb = ssb_i, tsb = tsb_i, rec = rec_i))
    assign(value = append(get("res_trace", envir = trace_env), res_add), 
           x = "res_trace", envir = trace_env)
    if (isTRUE(minimise)) catch_i <- -catch_i
    return(catch_i)
  }
  
  ### first, check some values
  names(vals_ini) <- vals_ini
  res_ini <- lapply(vals_ini, mp_catch, input = input)
  
  ### use optimise - 1D golden-section search
  res_optimise_MSY <- optimise(f = mp_catch, input = input,
                               interval = c(lower, upper), 
                               lower = lower, upper = upper,
                               maximum = TRUE,
                               tol = tol)
  
  ### get results and format
  res_trace_list <- unique(get("res_trace", envir = trace_env))
  res_trace <- as.data.frame(do.call(rbind, res_trace_list))
  res_trace <- as.data.frame(apply(res_trace, 2, unlist))
  res_trace <- unique(res_trace)
  
  
  if (isTRUE(plot)) {
    ### plot 
    p <- res_trace %>%
      select(Ftrgt, catch, ssb, rec) %>%
      pivot_longer(cols = c("catch", "ssb", "rec")) %>%
      mutate(value = value/1000,
             name = factor(name, levels = c("catch", "ssb", "rec"), 
                           labels = c("Catch (1000t)", "SSB (1000t)",
                                      "Recruitment (millions)"))) %>%
      ggplot(aes(x = Ftrgt, y = value)) +
      geom_point(size = 0.8) +
      stat_smooth(aes(alpha = "Loess smoother"), linewidth = 0.5,
                  se = FALSE, span = 0.3, n = 100, show.legend = TRUE) + 
      scale_alpha_manual("", values = 1) +
      facet_wrap(~ name, scales = "free_y", strip.position = "left") +
      labs(x = x_label, y = "") +
      ylim(c(0, NA)) +
      scale_x_continuous(breaks = seq(0, 1, 0.2)) +
      theme_bw() +
      theme(legend.position = "inside",
            legend.position.inside = c(0.85, 0.2),
            legend.background = element_blank(),
            legend.key = element_blank(),
            strip.placement = "outside",
            strip.background = element_blank(),
            axis.title.y = element_blank())
    ggsave(paste0(path, "MSY_search.png"), plot = p,
           width = 17, height = 6, units = "cm", dpi = 300, type = "cairo")
    ggsave(paste0(path, "MSY_search.pdf"), plot = p,
           width = 17, height = 6, units = "cm")
  } else {
    p <- NULL
  }
  if (isTRUE(save)) {
    saveRDS(res_trace_list, file = paste0(path, "MSY_trace.rds"))
    write.csv(res_trace, file = paste0(path, "MSY_trace.csv"), 
              row.names = FALSE)
  }
  
  return(list(plot = p, result = res_trace))
  
}




